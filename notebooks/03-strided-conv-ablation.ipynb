{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14651542,"sourceType":"datasetVersion","datasetId":9359657},{"sourceId":14655404,"sourceType":"datasetVersion","datasetId":9362270}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Task 4 – MaxPool2d to Strided Convolution Ablation","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade wandb","metadata":{"_uuid":"605fc072-91c7-407a-90b8-de734e759259","_cell_guid":"53f1c7a3-6a5a-45fc-a8c3-11a8bc774e43","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-01-28T19:01:20.917274Z","iopub.execute_input":"2026-01-28T19:01:20.917558Z","iopub.status.idle":"2026-01-28T19:01:40.209974Z","shell.execute_reply.started":"2026-01-28T19:01:20.917532Z","shell.execute_reply":"2026-01-28T19:01:40.209081Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.2)\nCollecting wandb\n  Downloading wandb-0.24.0-py3-none-manylinux_2_28_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (26.0rc2)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.1)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.5)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.42.1)\nRequirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2026.1.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nDownloading wandb-0.24.0-py3-none-manylinux_2_28_x86_64.whl (22.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.8/22.8 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.22.2\n    Uninstalling wandb-0.22.2:\n      Successfully uninstalled wandb-0.22.2\nSuccessfully installed wandb-0.24.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"_uuid":"45e59b58-3538-4493-bb3e-cc512a602efb","_cell_guid":"db657a60-7096-4660-9f85-8cc6b63e2da1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-01-28T19:01:50.965177Z","iopub.execute_input":"2026-01-28T19:01:50.965838Z","iopub.status.idle":"2026-01-28T19:02:07.733861Z","shell.execute_reply.started":"2026-01-28T19:01:50.965800Z","shell.execute_reply":"2026-01-28T19:02:07.733029Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n  | |_| | '_ \\/ _` / _` |  _/ -_)\n\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  2\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjain5\u001b[0m (\u001b[33mjain5-university-of-potsdam\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/src-cilp-assessment\")","metadata":{"_uuid":"7ae4e626-3926-4522-b635-3aa474754691","_cell_guid":"9278d885-1258-451a-a01b-a18fc0a6b3d6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-01-28T19:02:27.709927Z","iopub.execute_input":"2026-01-28T19:02:27.710534Z","iopub.status.idle":"2026-01-28T19:02:27.715047Z","shell.execute_reply.started":"2026-01-28T19:02:27.710498Z","shell.execute_reply":"2026-01-28T19:02:27.714306Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from src import models\nimport importlib\nimportlib.reload(models)\n\nfrom src.models import (\n    IntermediateFusionHadamardMaxPool,\n    IntermediateFusionHadamardStrided,\n)","metadata":{"_uuid":"a8b63f16-25b4-49da-bca3-b36852af8a24","_cell_guid":"a5ed9335-3c98-49a4-ae7e-aea10b817ed2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-01-28T19:03:00.467957Z","iopub.execute_input":"2026-01-28T19:03:00.468450Z","iopub.status.idle":"2026-01-28T19:03:03.833960Z","shell.execute_reply.started":"2026-01-28T19:03:00.468418Z","shell.execute_reply":"2026-01-28T19:03:03.833159Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\n\nDATA_ROOT = \"/kaggle/input/cilp-assessment-data/assessment\"\nprint(\"DATA_ROOT exists:\", os.path.exists(DATA_ROOT))\nprint(\"Cubes RGB:\", len(os.listdir(os.path.join(DATA_ROOT, \"cubes\", \"rgb\"))))\nprint(\"Cubes LiDAR:\", len(os.listdir(os.path.join(DATA_ROOT, \"cubes\", \"lidar\"))))\nprint(\"Spheres RGB:\", len(os.listdir(os.path.join(DATA_ROOT, \"spheres\", \"rgb\"))))\nprint(\"Spheres LiDAR:\", len(os.listdir(os.path.join(DATA_ROOT, \"spheres\", \"lidar\"))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:03:45.739389Z","iopub.execute_input":"2026-01-28T19:03:45.740334Z","iopub.status.idle":"2026-01-28T19:03:46.108375Z","shell.execute_reply.started":"2026-01-28T19:03:45.740301Z","shell.execute_reply":"2026-01-28T19:03:46.107779Z"}},"outputs":[{"name":"stdout","text":"DATA_ROOT exists: True\nCubes RGB: 9999\nCubes LiDAR: 9999\nSpheres RGB: 9999\nSpheres LiDAR: 9999\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nfrom pathlib import Path","metadata":{"_uuid":"d3c87cd1-391b-402a-917f-3e1ae1b04654","_cell_guid":"a98ec3c2-8ae9-47c6-a096-cd39edfecb7a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2026-01-28T19:04:00.830709Z","iopub.execute_input":"2026-01-28T19:04:00.831415Z","iopub.status.idle":"2026-01-28T19:04:04.110572Z","shell.execute_reply.started":"2026-01-28T19:04:00.831380Z","shell.execute_reply":"2026-01-28T19:04:04.109979Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class SimpleCILPDataset(Dataset):\n    def __init__(self, root, split=\"train\", transform=None, seed=42):\n        self.transform = transform\n        self.samples = []\n\n        rng = np.random.RandomState(seed)\n\n        for label_name, label_id in [(\"cubes\", 0), (\"spheres\", 1)]:\n            rgb_dir = Path(root) / label_name / \"rgb\"\n            lidar_dir = Path(root) / label_name / \"lidar\"\n\n            rgb = {p.stem: p for p in rgb_dir.glob(\"*.png\")}\n            lidar = {p.stem: p for p in lidar_dir.glob(\"*.npy\")}\n\n            common = sorted(set(rgb) & set(lidar))\n            rng.shuffle(common)\n\n            split_idx = int(0.8 * len(common))\n            selected = common[:split_idx] if split == \"train\" else common[split_idx:]\n\n            for stem in selected:\n                self.samples.append((\n                    rgb[stem],\n                    lidar[stem],\n                    label_id\n                ))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        rgb_path, lidar_path, label = self.samples[idx]\n\n        rgb = Image.open(rgb_path).convert(\"RGB\")\n        if self.transform:\n            rgb = self.transform(rgb)\n\n        lidar = torch.tensor(np.load(lidar_path), dtype=torch.float32)\n        label = torch.tensor(label, dtype=torch.long)\n\n        return rgb, lidar, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:04:21.633810Z","iopub.execute_input":"2026-01-28T19:04:21.634430Z","iopub.status.idle":"2026-01-28T19:04:21.642736Z","shell.execute_reply.started":"2026-01-28T19:04:21.634402Z","shell.execute_reply":"2026-01-28T19:04:21.641915Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor()\n])\n\ntrain_dataset = SimpleCILPDataset(DATA_ROOT, split=\"train\", transform=transform)\nval_dataset   = SimpleCILPDataset(DATA_ROOT, split=\"val\", transform=transform)\n\nprint(\"Train samples:\", len(train_dataset))\nprint(\"Val samples:\", len(val_dataset))\n\nrgb, lidar, label = train_dataset[0]\nprint(\"RGB:\", rgb.shape)\nprint(\"LiDAR:\", lidar.shape)\nprint(\"Label:\", label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:04:36.993808Z","iopub.execute_input":"2026-01-28T19:04:36.994358Z","iopub.status.idle":"2026-01-28T19:04:37.836878Z","shell.execute_reply.started":"2026-01-28T19:04:36.994328Z","shell.execute_reply":"2026-01-28T19:04:37.836179Z"}},"outputs":[{"name":"stdout","text":"Train samples: 15998\nVal samples: 4000\nRGB: torch.Size([3, 128, 128])\nLiDAR: torch.Size([64, 64])\nLabel: tensor(0)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"lidar_input_dim = 64 * 64\nprint(\"LiDAR input dim:\", lidar_input_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:05:04.289772Z","iopub.execute_input":"2026-01-28T19:05:04.290503Z","iopub.status.idle":"2026-01-28T19:05:04.294463Z","shell.execute_reply.started":"2026-01-28T19:05:04.290475Z","shell.execute_reply":"2026-01-28T19:05:04.293662Z"}},"outputs":[{"name":"stdout","text":"LiDAR input dim: 4096\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())\nprint(torch.cuda.get_device_name(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:05:15.817902Z","iopub.execute_input":"2026-01-28T19:05:15.818214Z","iopub.status.idle":"2026-01-28T19:05:15.922483Z","shell.execute_reply.started":"2026-01-28T19:05:15.818187Z","shell.execute_reply":"2026-01-28T19:05:15.921864Z"}},"outputs":[{"name":"stdout","text":"True\nTesla T4\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nBATCH_SIZE = 32 \n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:05:25.625893Z","iopub.execute_input":"2026-01-28T19:05:25.626186Z","iopub.status.idle":"2026-01-28T19:05:25.630742Z","shell.execute_reply.started":"2026-01-28T19:05:25.626162Z","shell.execute_reply":"2026-01-28T19:05:25.630057Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"rgb, lidar, label = next(iter(train_loader))\nprint(rgb.shape, lidar.shape, label.shape)\nprint(\"LiDAR input dim:\", lidar_input_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:05:40.682272Z","iopub.execute_input":"2026-01-28T19:05:40.683051Z","iopub.status.idle":"2026-01-28T19:05:41.581178Z","shell.execute_reply.started":"2026-01-28T19:05:40.683011Z","shell.execute_reply":"2026-01-28T19:05:41.580483Z"}},"outputs":[{"name":"stdout","text":"torch.Size([32, 3, 128, 128]) torch.Size([32, 64, 64]) torch.Size([32])\nLiDAR input dim: 4096\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def run_epoch(model, loader, criterion, optimizer=None, training=True):\n    if training:\n        model.train()\n    else:\n        model.eval()\n\n    total_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.set_grad_enabled(training):\n        for rgb, lidar, labels in loader:\n            rgb = rgb.to(device)\n            lidar = lidar.to(device)\n            labels = labels.to(device)\n\n            outputs = model(rgb, lidar)\n            loss = criterion(outputs, labels)\n\n            if training:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n            total_loss += loss.item() * labels.size(0)\n            preds = outputs.argmax(dim=1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n    avg_loss = total_loss / total\n    accuracy = correct / total\n    return avg_loss, accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:14:19.729539Z","iopub.execute_input":"2026-01-28T19:14:19.730204Z","iopub.status.idle":"2026-01-28T19:14:19.737670Z","shell.execute_reply.started":"2026-01-28T19:14:19.730176Z","shell.execute_reply":"2026-01-28T19:14:19.737050Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:14:22.671354Z","iopub.execute_input":"2026-01-28T19:14:22.671676Z","iopub.status.idle":"2026-01-28T19:14:22.676784Z","shell.execute_reply.started":"2026-01-28T19:14:22.671645Z","shell.execute_reply":"2026-01-28T19:14:22.676003Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nimport time\nimport wandb\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ndef train_variant(model_class, variant_name, lidar_input_dim,\n                  train_loader, val_loader,\n                  embedding_dim=128, num_classes=2,\n                  epochs=10, lr=1e-3,\n                  project=\"cilp-extended-assessment\"):\n\n    model = model_class(\n        lidar_input_dim=lidar_input_dim,\n        embedding_dim=embedding_dim,\n        num_classes=num_classes,\n    ).to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    num_params = count_parameters(model)\n\n    wandb.init(\n        project=project,\n        name=f\"task4-{variant_name}\",\n        config={\n            \"task\": \"task4_strided_ablation\",\n            \"fusion_strategy\": \"intermediate_hadamard\",\n            \"downsampling\": variant_name,          # \"maxpool\" or \"strided_conv\"\n            \"model_architecture\": model.__class__.__name__,\n            \"embedding_size\": embedding_dim,\n            \"batch_size\": train_loader.batch_size,\n            \"learning_rate\": lr,\n            \"optimizer\": optimizer.__class__.__name__,\n            \"epochs\": epochs,\n            \"num_parameters\": num_params,\n            \"dataset\": \"cilp-assessment\",\n        },\n    )\n\n    start_time = time.time()\n\n    for epoch in range(1, epochs + 1):\n        train_loss, train_acc = run_epoch(model, train_loader, criterion, optimizer, training=True)\n        val_loss, val_acc = run_epoch(model, val_loader, criterion, optimizer, training=False)\n\n        current_lr = optimizer.param_groups[0][\"lr\"]\n\n        print(\n            f\"[{variant_name}] Epoch {epoch} \"\n            f\"Train Loss {train_loss:.4f}, Train Acc {train_acc:.4f} \"\n            f\"Val Loss {val_loss:.4f}, Val Acc {val_acc:.4f}\"\n        )\n\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss,\n            \"train_acc\": train_acc,\n            \"val_loss\": val_loss,\n            \"val_acc\": val_acc,\n            \"learning_rate\": current_lr,\n        })\n\n    total_training_time = time.time() - start_time\n    time_per_epoch = total_training_time / epochs\n\n    logs = {\n        \"total_training_time_sec\": total_training_time,\n        \"time_per_epoch_sec\": time_per_epoch,\n    }\n\n    if torch.cuda.is_available():\n        max_mem_mb = torch.cuda.max_memory_allocated() / (1024 ** 2)\n        logs[\"max_gpu_memory_mb\"] = max_mem_mb\n\n    wandb.log(logs)\n    wandb.finish()\n\n    return {\n        \"variant\": variant_name,\n        \"num_parameters\": num_params,\n        \"total_training_time_sec\": total_training_time,\n        \"time_per_epoch_sec\": time_per_epoch,\n        \"max_gpu_memory_mb\": logs.get(\"max_gpu_memory_mb\", None),\n        \"final_train_loss\": train_loss,\n        \"final_train_acc\": train_acc,\n        \"final_val_loss\": val_loss,\n        \"final_val_acc\": val_acc,\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:14:24.593826Z","iopub.execute_input":"2026-01-28T19:14:24.594550Z","iopub.status.idle":"2026-01-28T19:14:24.605067Z","shell.execute_reply.started":"2026-01-28T19:14:24.594524Z","shell.execute_reply":"2026-01-28T19:14:24.604303Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"results = []\n\nres_maxpool = train_variant(\n    IntermediateFusionHadamardMaxPool,\n    variant_name=\"maxpool\",\n    lidar_input_dim=lidar_input_dim,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    epochs=10,\n    lr=1e-3,\n)\nresults.append(res_maxpool)\n\nres_strided = train_variant(\n    IntermediateFusionHadamardStrided,\n    variant_name=\"strided_conv\",\n    lidar_input_dim=lidar_input_dim,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    epochs=10,\n    lr=1e-3,\n)\nresults.append(res_strided)\n\nresults\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T19:14:28.265245Z","iopub.execute_input":"2026-01-28T19:14:28.265499Z","iopub.status.idle":"2026-01-28T19:24:39.974769Z","shell.execute_reply.started":"2026-01-28T19:14:28.265478Z","shell.execute_reply":"2026-01-28T19:24:39.974135Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing previous runs because reinit is set to 'default'."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">task4-maxpool</strong> at: <a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment/runs/31qqbi6u' target=\"_blank\">https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment/runs/31qqbi6u</a><br> View project at: <a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260128_191207-31qqbi6u/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.24.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260128_191428-8foejqs0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment/runs/8foejqs0' target=\"_blank\">task4-maxpool</a></strong> to <a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment/runs/8foejqs0' target=\"_blank\">https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment/runs/8foejqs0</a>"},"metadata":{}},{"name":"stdout","text":"[maxpool] Epoch 1 Train Loss 0.3873, Train Acc 0.8274 Val Loss 0.1080, Val Acc 0.9643\n[maxpool] Epoch 2 Train Loss 0.0892, Train Acc 0.9692 Val Loss 0.0595, Val Acc 0.9812\n[maxpool] Epoch 3 Train Loss 0.0348, Train Acc 0.9878 Val Loss 0.0340, Val Acc 0.9895\n[maxpool] Epoch 4 Train Loss 0.0225, Train Acc 0.9927 Val Loss 0.0212, Val Acc 0.9928\n[maxpool] Epoch 5 Train Loss 0.0212, Train Acc 0.9924 Val Loss 0.0141, Val Acc 0.9962\n[maxpool] Epoch 6 Train Loss 0.0210, Train Acc 0.9937 Val Loss 0.0047, Val Acc 0.9990\n[maxpool] Epoch 7 Train Loss 0.0282, Train Acc 0.9878 Val Loss 0.0534, Val Acc 0.9890\n[maxpool] Epoch 8 Train Loss 0.0188, Train Acc 0.9939 Val Loss 0.0064, Val Acc 0.9980\n[maxpool] Epoch 9 Train Loss 0.0139, Train Acc 0.9951 Val Loss 0.0186, Val Acc 0.9940\n[maxpool] Epoch 10 Train Loss 0.0103, Train Acc 0.9970 Val Loss 0.0384, Val Acc 0.9882\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_gpu_memory_mb</td><td>▁</td></tr><tr><td>time_per_epoch_sec</td><td>▁</td></tr><tr><td>total_training_time_sec</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▇████████</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▇▇█▆█▇▆</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▁▄▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>max_gpu_memory_mb</td><td>314.08105</td></tr><tr><td>time_per_epoch_sec</td><td>34.98906</td></tr><tr><td>total_training_time_sec</td><td>349.89065</td></tr><tr><td>train_acc</td><td>0.997</td></tr><tr><td>train_loss</td><td>0.01035</td></tr><tr><td>val_acc</td><td>0.98825</td></tr><tr><td>val_loss</td><td>0.03839</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">task4-maxpool</strong> at: <a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment/runs/8foejqs0' target=\"_blank\">https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment/runs/8foejqs0</a><br> View project at: <a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260128_191428-8foejqs0/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.24.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260128_192025-qlwfrzb9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment/runs/qlwfrzb9' target=\"_blank\">task4-strided_conv</a></strong> to <a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment/runs/qlwfrzb9' target=\"_blank\">https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment/runs/qlwfrzb9</a>"},"metadata":{}},{"name":"stdout","text":"[strided_conv] Epoch 1 Train Loss 0.3907, Train Acc 0.8258 Val Loss 0.1019, Val Acc 0.9708\n[strided_conv] Epoch 2 Train Loss 0.1095, Train Acc 0.9657 Val Loss 0.0752, Val Acc 0.9802\n[strided_conv] Epoch 3 Train Loss 0.0339, Train Acc 0.9899 Val Loss 0.0184, Val Acc 0.9935\n[strided_conv] Epoch 4 Train Loss 0.0170, Train Acc 0.9943 Val Loss 0.0529, Val Acc 0.9808\n[strided_conv] Epoch 5 Train Loss 0.0142, Train Acc 0.9952 Val Loss 0.0151, Val Acc 0.9955\n[strided_conv] Epoch 6 Train Loss 0.0112, Train Acc 0.9966 Val Loss 0.0179, Val Acc 0.9940\n[strided_conv] Epoch 7 Train Loss 0.0116, Train Acc 0.9959 Val Loss 0.0176, Val Acc 0.9938\n[strided_conv] Epoch 8 Train Loss 0.0072, Train Acc 0.9975 Val Loss 0.0059, Val Acc 0.9985\n[strided_conv] Epoch 9 Train Loss 0.0086, Train Acc 0.9977 Val Loss 0.0166, Val Acc 0.9962\n[strided_conv] Epoch 10 Train Loss 0.0070, Train Acc 0.9977 Val Loss 0.0186, Val Acc 0.9950\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_gpu_memory_mb</td><td>▁</td></tr><tr><td>time_per_epoch_sec</td><td>▁</td></tr><tr><td>total_training_time_sec</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▇████████</td></tr><tr><td>train_loss</td><td>█▃▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▇▄▇▇▇█▇▇</td></tr><tr><td>val_loss</td><td>█▆▂▄▂▂▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>max_gpu_memory_mb</td><td>314.08105</td></tr><tr><td>time_per_epoch_sec</td><td>24.76186</td></tr><tr><td>total_training_time_sec</td><td>247.61857</td></tr><tr><td>train_acc</td><td>0.99775</td></tr><tr><td>train_loss</td><td>0.00704</td></tr><tr><td>val_acc</td><td>0.995</td></tr><tr><td>val_loss</td><td>0.01858</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">task4-strided_conv</strong> at: <a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment/runs/qlwfrzb9' target=\"_blank\">https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment/runs/qlwfrzb9</a><br> View project at: <a href='https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/jain5-university-of-potsdam/cilp-extended-assessment</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260128_192025-qlwfrzb9/logs</code>"},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[{'variant': 'maxpool',\n  'num_parameters': 1208258,\n  'total_training_time_sec': 349.8906464576721,\n  'time_per_epoch_sec': 34.989064645767215,\n  'max_gpu_memory_mb': 314.0810546875,\n  'final_train_loss': 0.01034719538028868,\n  'final_train_acc': 0.9969996249531191,\n  'final_val_loss': 0.03839003745937316,\n  'final_val_acc': 0.98825},\n {'variant': 'strided_conv',\n  'num_parameters': 1254434,\n  'total_training_time_sec': 247.6185712814331,\n  'time_per_epoch_sec': 24.761857128143312,\n  'max_gpu_memory_mb': 314.0810546875,\n  'final_train_loss': 0.007042125709639877,\n  'final_train_acc': 0.9977497187148393,\n  'final_val_loss': 0.01858437018224143,\n  'final_val_acc': 0.995}]"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"## Task 4 – Strided Convolution Ablation\n\nIn this task, I compare two intermediate Hadamard fusion models that differ only in how the RGB encoder downsamples spatially: the baseline uses MaxPool2d, while the variant replaces each pooling operation with a stride‑2 convolution. Both models share the same LiDAR encoder, embedding dimension, fusion MLP, optimizer, learning rate and number of epochs, so differences in performance can be attributed to the downsampling strategy.\n\n| Metric                 | MaxPool2d      | Strided Conv    | Difference (Strided − MaxPool) |\n|------------------------|----------------|-----------------|--------------------------------|\n| Parameters             | 1,208,258      | 1,254,434       | +46,176                        |\n| Max GPU memory (MB)    | 314.08         | 314.08          | 0                              |\n| Time per epoch (s)     | 34.99          | 24.76           | −10.23                         |\n| Total train time (s)   | 349.89         | 247.62          | −102.27                        |\n| Final train loss       | 0.01035        | 0.00704         | −0.00331                       |\n| Final val loss         | 0.03839        | 0.01858         | −0.01981                       |\n| Final train accuracy   | 0.99700        | 0.99775         | +0.00075                       |\n| Final val accuracy     | 0.98825        | 0.99500         | +0.00675                       |\n\nThe results show that the strided‑convolution encoder is both more efficient and more accurate than the MaxPool2d baseline on this dataset. Although it uses slightly more parameters (+46k, about 3.8% increase), the strided model reduces time per epoch by roughly 10 seconds and total training time by more than 100 seconds, while keeping GPU memory usage identical. This suggests that replacing discrete pooling with learned stride‑2 convolutions can exploit GPU throughput better and avoid some of the information loss introduced by hard pooling operations.\n\nFrom a generalization perspective, the strided model attains lower training and validation losses and improves validation accuracy from 98.8% to 99.5%, indicating a clear performance benefit rather than mere overfitting. Intuitively, the stride‑2 convolutions allow the network to learn how to downsample and preserve task‑relevant structure, instead of applying a fixed max operation that might discard useful shape cues. Given these findings, I would choose the strided‑convolution encoder as the preferred design for subsequent experiments, since it offers better accuracy and faster training with only a modest increase in parameter count.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}